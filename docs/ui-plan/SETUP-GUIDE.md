# MVP Setup & Testing Guide

## Quick Start

### 1. Install Dependencies (if needed)
```bash
cd /Users/seyitanoke/Documents/Nora/ai-companion
npm install
```

### 2. Start Development Server
```bash
npm run dev
# or
vite
```

### 3. Open Browser
Navigate to: `http://localhost:5173` (or the port shown in terminal)

### 4. Open Browser Console
Press `F12` or `Cmd+Option+I` (Mac) to open DevTools and view console logs

---

## Testing the Audio Pipeline

### Step 1: Initial Load
**Expected Console Output:**
```
[UI] VoiceChatScreen mounted
[UI] Initial state: idle
```

**Visual Check:**
- Page loads with greeting "Hi Mary, I'm looking forward..."
- "Let's Talk" button is visible
- Status shows "idle" with gray dot
- Debug info shows at bottom

---

### Step 2: Click "Let's Talk" Button

**Expected Console Output:**
```
[UI] User clicked start button
[UI] ğŸš€ Starting voice chat session...
[UI] State transition: idle â†’ requesting_permissions
[AUDIO] ğŸ¤ Initializing audio recorder...
[AUDIO] Requesting microphone permissions...
```

**Browser Popup:**
- Browser will ask for microphone permission
- Click "Allow"

**After Permission Granted:**
```
[AUDIO] âœ“ Microphone access granted <device name>
[AUDIO] Creating AudioContext (16000Hz)...
[AUDIO] âœ“ AudioContext created { sampleRate: 16000, state: "running" }
[AUDIO] Loading audio worklet processor...
[AUDIO] âœ“ Worklet processor loaded
[AUDIO] Creating AudioWorkletNode...
[AUDIO] Connecting audio pipeline...
[AUDIO] âœ“ Audio pipeline connected: Mic â†’ Worklet
[AUDIO] âœ… Audio recorder initialized successfully

[AUDIO] ğŸ”Š Initializing audio player...
[AUDIO] Creating AudioContext (24000Hz)...
[AUDIO] âœ“ AudioContext created { sampleRate: 24000, state: "running" }
[AUDIO] Loading audio worklet processor...
[AUDIO] âœ“ Worklet processor loaded
[AUDIO] Creating AudioWorkletNode...
[AUDIO] Connecting audio pipeline...
[AUDIO] âœ“ Audio pipeline connected: Worklet â†’ Speakers
[AUDIO] âœ… Audio player initialized successfully

[UI] State transition: requesting_permissions â†’ connecting_ws
[WEBSOCKET] ğŸ”Œ Connecting to WebSocket... ws://localhost:8000/ws/<uuid>?is_audio=true
[WEBSOCKET] Generated session ID: <uuid>
```

**Visual Check:**
- Button text changes to "Connecting..."
- Status shows "connecting_ws" with yellow dot
- Avatar pulse animation should start

---

### Step 3: WebSocket Connection

**Expected Console Output (Success):**
```
[WEBSOCKET] âœ“ Connection opened
[WEBSOCKET] Connection state: OPEN
[UI] State transition: connecting_ws â†’ ready
```

**Expected Console Output (Failure):**
```
[WEBSOCKET] âŒ Connection error Event { ... }
[WEBSOCKET] Will retry in 5000ms
[UI] State transition: connecting_ws â†’ connection_error
```

**Visual Check (Success):**
- Button text changes to "Stop Talking"
- Status shows "ready" with green dot
- Avatar pulse is active

---

### Step 4: Speaking (Audio Recording)

**While speaking into microphone, expected output every 200ms:**
```
[AUDIO] Received audio chunk: 3200 samples
[AUDIO] Converting Float32 to PCM16, samples: 3200
[AUDIO] PCM16 conversion complete, bytes: 6400
[AUDIO] Sending buffered audio: 1 chunks
[AUDIO] Converting ArrayBuffer to Base64, size: 6400 bytes
[AUDIO] Base64 conversion complete, output length: 8534
[WEBSOCKET] Sending audio data: 8534 chars (base64)
[WEBSOCKET] â†’ [CLIENT TO AGENT] { mime_type: "audio/pcm", data_length: 8534 }
[AUDIO] Audio buffer cleared
```

**Visual Check:**
- Status should show "listening" when actively sending audio
- No lag or freezing

---

### Step 5: Receiving Response

**Expected Console Output (Text Response):**
```
[WEBSOCKET] â† [AGENT TO CLIENT] { mime_type: "text/plain", data_length: 25, ... }
[UI] Received text from server: Hello! How can I help you?
```

**Expected Console Output (Audio Response):**
```
[WEBSOCKET] â† [AGENT TO CLIENT] { mime_type: "audio/pcm", data_length: 12000, ... }
[AUDIO] Received audio from server
[AUDIO] Converting Base64 to ArrayBuffer, input length: 12000
[AUDIO] ArrayBuffer conversion complete, size: 9000 bytes
[AUDIO] Enqueueing audio to player: 5625 samples
[AUDIO] âœ“ Audio data sent to worklet
```

**Visual Check:**
- Text appears in transcript area
- Audio plays through speakers
- Status changes to "speaking" with purple dot

**Expected Console Output (Turn Complete):**
```
[WEBSOCKET] â† [AGENT TO CLIENT] { turn_complete: true }
[UI] Turn complete signal received
[UI] State transition: speaking â†’ ready
```

---

### Step 6: Stop Session

**Click "Stop Talking" button:**
```
[UI] User clicked stop button
[UI] ğŸ›‘ Stopping voice chat session...
[UI] State transition: ready â†’ idle

[AUDIO] ğŸ›‘ Stopping audio recorder...
[AUDIO] âœ“ Source node disconnected
[AUDIO] âœ“ Worklet node disconnected
[AUDIO] âœ“ Media track stopped <device name>
[AUDIO] âœ“ AudioContext closed
[AUDIO] âœ… Audio recorder stopped and cleaned up

[AUDIO] ğŸ›‘ Stopping audio player...
[AUDIO] âœ“ Player worklet disconnected
[AUDIO] âœ“ Player AudioContext closed
[AUDIO] âœ… Audio player stopped

[WEBSOCKET] Closing WebSocket connection...
[WEBSOCKET] âœ“ Connection closed gracefully
[UI] âœ… Session stopped
```

**Visual Check:**
- Button returns to "Let's Talk"
- Status returns to "idle" with gray dot
- Avatar pulse stops
- Transcript remains visible

---

## Troubleshooting

### Issue: "Cannot find module '../../../static/js/pcm-recorder-processor.js'"

**Solution:**
The worklet files must be in the `static/js/` directory. Verify they exist:
```bash
ls -la static/js/
```

Should show:
- `pcm-player-processor.js`
- `pcm-recorder-processor.js`

### Issue: Microphone permission denied

**Console Output:**
```
[ERROR] âŒ Failed to initialize audio recorder NotAllowedError: Permission denied
[UI] State transition: idle â†’ permission_denied
```

**Solution:**
1. Check browser settings â†’ Privacy â†’ Microphone
2. Ensure localhost is allowed
3. Try in a different browser
4. On Mac: System Preferences â†’ Security & Privacy â†’ Microphone

### Issue: WebSocket connection fails

**Console Output:**
```
[WEBSOCKET] âŒ Connection error
[WEBSOCKET] ğŸ”„ Auto-reconnect triggered
```

**Solution:**
1. Verify backend server is running
2. Check the WebSocket URL in console
3. Ensure port matches server (default: 8000)
4. Check firewall settings

### Issue: No audio chunks appearing

**Solution:**
1. Verify mic is not muted
2. Check browser microphone permissions
3. Look for AudioContext state in console
4. Try speaking louder

### Issue: Audio sounds distorted

**Solution:**
1. Check sample rate mismatch in console logs
2. Verify PCM16 conversion is working
3. Check for buffer overflow warnings
4. Reduce system audio volume

---

## Configuration

### Change WebSocket URL

Edit `src/services/websocket-service.js`:
```javascript
// Line ~47
const wsHost = window.location.host || 'localhost:8000';
// Change to your server address
```

### Change Audio Settings

Edit `src/config/audio-config.js`:
```javascript
RECORDER_SAMPLE_RATE: 16000,  // Recording sample rate
PLAYER_SAMPLE_RATE: 24000,    // Playback sample rate
BUFFER_INTERVAL_MS: 200,      // Audio chunk interval
DEBUG: true,                   // Enable/disable console logs
```

### Disable Debug Logs

In `src/config/audio-config.js`:
```javascript
DEBUG: false,  // Set to false to disable verbose logging
```

---

## Production Checklist

Before deploying to production:

1. âœ… Set `DEBUG: false` in audio-config.js
2. âœ… Remove debug info panel from VoiceChatScreen.jsx
3. âœ… Replace avatar placeholder with Figma design
4. âœ… Add proper error boundaries
5. âœ… Test on multiple browsers (Chrome, Safari, Firefox)
6. âœ… Test on mobile devices
7. âœ… Add analytics/monitoring
8. âœ… Implement proper reconnection UX
9. âœ… Add loading skeletons
10. âœ… Optimize bundle size

---

## Next Steps

After MVP is working:

1. **Enhance UI** - Implement full Figma design
2. **Add Animations** - Framer Motion for smooth transitions
3. **Improve UX** - Better error handling, loading states
4. **Add Features** - Conversation history, settings panel
5. **Performance** - Optimize audio buffering, reduce latency
6. **Accessibility** - Keyboard navigation, screen reader support
7. **Testing** - Unit tests, integration tests, E2E tests

---

## File Structure Reference

```
src/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ audio-config.js          âœ… Audio settings & logger
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ base64.js                âœ… Encoding/decoding utilities
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ audio-recorder.js    âœ… Mic capture
â”‚   â”‚   â””â”€â”€ audio-player.js      âœ… Audio playback
â”‚   â””â”€â”€ websocket-service.js     âœ… WebSocket client
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useVoiceChat.js          âœ… Main orchestrator hook
â”œâ”€â”€ components/
â”‚   â””â”€â”€ voice-chat/
â”‚       â”œâ”€â”€ VoiceChatScreen.jsx  âœ… Main UI component
â”‚       â””â”€â”€ VoiceChatScreen.css  âœ… Styles
â””â”€â”€ App.jsx                      âœ… Updated with VoiceChatScreen

static/js/
â”œâ”€â”€ pcm-player-processor.js      âœ… Audio worklet (playback)
â””â”€â”€ pcm-recorder-processor.js    âœ… Audio worklet (recording)

docs/ui-plan/
â”œâ”€â”€ ARCHITECTURE.md              âœ… Architecture overview
â”œâ”€â”€ MVP-TESTING.md               âœ… Testing guide
â””â”€â”€ SETUP-GUIDE.md               âœ… This file
```
